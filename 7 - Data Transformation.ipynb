{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "pd.options.mode.chained_assignment = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We begin by defining a pandas dataframe that contains some cells with missing values. Note that pandas, in addition to allowing us to create dataframes from a variety of files, also supports explicit declaration."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame(np.arange(5 * 4). reshape(5, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Sampling"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To select a random subset without replacement, one way is to slice off the first k elements of the array returned by permutation, where k is the desired subset size. Here, we use the 'take' method, which retrieves elements along a given axis at the given indices. Using this function, we slice off the first three elements:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sampled_without_replacement = df.take(np.random.permutation(len(df))[:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sampled_without_replacement"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To generate a sample with replacement, we can draw random integers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampler = np.random.randint(0, len(df), size=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These random integers can be used as input for the 'take' method, which is then used to sample the data. Since the random integers consistuting the array may be repeated, the rows sampled by this method may also be repeated -- or, in other words, sampled with replacement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sampled_with_replacement = df.take(sampler)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sampled_with_replacement"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Normalization or Standardization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aside from sampling data, we may also want to normalize or standardize our data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm = df / df.sum().astype('float')\n",
      "df_norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perm = np.random.permutation(len(df))\n",
      "perm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_permuted = df.take(perm)\n",
      "df_permuted"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_permuted_norm = df_permuted / df_permuted.sum().astype('float')\n",
      "df_permuted_norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The Iris Dataset as an Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use the \"Iris dataset\" as an example for employing these methods. The Iris flower dataset or Fisher's Iris dataset is a well-known multivariate dataset introduced by Sir Ronald Fisher in 1936 as an example of discriminant analysis, a method for finding a linear combination of features that characterizes or separates two or more classes of objects or events. Fischer is famous for helping to develop the foundation for modern statistical science, and his method of linear discriminant analysis is perhaps the earliest classification method.\n",
      "\n",
      "Let's fetch the Iris dataset from the UCI Machine Learning repository."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileURL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
      "data = pd.read_csv(fileURL, names=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width', 'Name'], header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When read directly from the UCI Machine Learning repository, the Iris dataset has an extra line at the bottom that is read by pandas as a row of null values. Let's drop this final line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_data = data.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To visualize this data, we can create a scatter plot matrix. In pandas, the scatter_matrix function generates a matrix of pairwise scatterplots, optiorally with histograms (or kernel density estimates) on the diagonal. Here's the scatter plot matrix with histograms on the diagonal:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_colors = ['g', 'b','r','c']\n",
      "pl1 = pd.tools.plotting.scatter_matrix(iris_data, diagonal='hist', figsize=(10,10), color=my_colors, s=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also use boxplots to visualize the variability of each feature:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl2 = iris_data.boxplot(grid=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that Sepal Width has several outliers. In certain circumstances, it may be beneficial to remove these outliers. In this example, we interpolate over these outliers, replacing them with values that are more likely given the other data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_data['Sepal Width'] = np.where((iris_data['Sepal Width'] > 4) | (iris_data['Sepal Width'] < 2.1), np.nan, iris_data['Sepal Width'])\n",
      "iris_data['Sepal Width'] = iris_data['Sepal Width'].interpolate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once again using boxplots to visualize the data, notice that the outliers are now absent:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl3 = iris_data.boxplot(grid=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With outliers removed, we may now be interested in sampling the data. Here, we use sampling with replacement to select 100 instances from the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampler = np.random.randint(0, len(iris_data), size=100)\n",
      "iris_data = iris_data.take(sampler)\n",
      "iris_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now with the data cleaned and sampled, we may be interested in standardizing the data. Here, we use z-score normalization to rescale each feature. z-score normalization converts all features to a common scale with an average of zero and standard deviation of one:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_data = iris_data.groupby('Name').transform(lambda x: (x-x.mean())/x.std(ddof=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using boxplots once again, now we can see that each feature has been normalized, with each feature displaying an average of zero and a standard deviation of one:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl4 = iris_data.boxplot(grid=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualizating the data with a scatter plot matrix once again, we can now observe dramatic changes in the data. Each feature now displays a histogram that more closely resembles a normal distribution. Additionally, the separation previously observable in the scatter plots is now largely absent.\n",
      "\n",
      "Depending on the objectives, these changes could be beneficial or detrimental. The use of data sampling, outlier removal, and data normalization are steps that depend critically the methods being employed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl5 = pd.tools.plotting.scatter_matrix(iris_data, diagonal='hist', figsize=(10,10), color=my_colors, s=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}