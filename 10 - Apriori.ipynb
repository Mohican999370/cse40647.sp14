{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Modified from \"https://gist.github.com/marcelcaraciolo/1423287\"."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Function Definitions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_candidates(dataset):\n",
      "    '''Creates a list of candidate itemsets of size one from a list of transactions.\n",
      "\n",
      "    Args:\n",
      "      dataset (array): The dataset (an array of transactions) from which to generate \n",
      "        candidate itemsets.\n",
      "\n",
      "    Returns:\n",
      "      frozenset mapping of c1: The list of candidate itemsets (c1) passed as a \n",
      "        frozenset (a set that is immutable and hashable).\n",
      "\n",
      "    '''\n",
      "\n",
      "    c1 = [] # list of all items in the database of transactions\n",
      "    for transaction in dataset:\n",
      "        for item in transaction:\n",
      "            if not [item] in c1:\n",
      "                c1.append([item])\n",
      "    c1.sort()\n",
      "\n",
      "    # map c1 to a frozenset because it will be the key of a dictionary\n",
      "    return map(frozenset, c1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def support_prune(dataset, candidates, min_support):\n",
      "    '''Returns all candidate itemsets that meet a minimum support threshold.\n",
      "    \n",
      "    By the apriori principle, if an itemset is frequent, then all of its subsets must\n",
      "    also be frequent. As a result, we can perform support-based pruning to systemically\n",
      "    control the exponential growth of candidate itemsets. Thus, itemsets that do not \n",
      "    meet the minimum support level are pruned from the input list of itemsets (dataset).\n",
      "\n",
      "    Args:\n",
      "      dataset (array): The dataset (an array of transactions) from which to generate \n",
      "        candidate itemsets.\n",
      "      candidates (frozenset): The list of candidate itemsets.\n",
      "      min_support (float): The minimum support threshold.\n",
      "\n",
      "    Returns:\n",
      "      retlist: The list of frequent itemsets.\n",
      "      support_data: The support data for all candidate itemsets.\n",
      "\n",
      "    '''\n",
      "\n",
      "    sscnt = {} # set for support counts\n",
      "    for tid in dataset:\n",
      "        for can in candidates:\n",
      "            if can.issubset(tid):\n",
      "                sscnt.setdefault(can, 0)\n",
      "                sscnt[can] += 1\n",
      " \n",
      "    num_items = float(len(dataset)) # total number of transactions in the dataset\n",
      "    retlist = [] # array for unpruned itemsets\n",
      "    support_data = {} # set for support data for corresponding itemsets\n",
      "    for key in sscnt:\n",
      "        # calculate the support of itemset key\n",
      "        support = sscnt[key] / num_items\n",
      "        if support >= min_support:\n",
      "            retlist.insert(0, key)\n",
      "        support_data[key] = support\n",
      "\n",
      "    return retlist, support_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def apriori_gen(freq_sets, k):\n",
      "    '''Generates the joint transactions from candidate itemsets.\n",
      "\n",
      "    Args:\n",
      "      freq_sets (array): The list of frequent itemsets.\n",
      "      k (int): The list of candidate itemsets.\n",
      "\n",
      "    Returns:\n",
      "      retlist: The list of joint candidate itemsets.\n",
      "\n",
      "    '''\n",
      "\n",
      "    retList = []\n",
      "    lenLk = len(freq_sets)\n",
      "    for i in range(lenLk):\n",
      "        for j in range(i+1, lenLk):\n",
      "            L1 = list(freq_sets[i])[:k-2]\n",
      "            L2 = list(freq_sets[j])[:k-2]\n",
      "            L1.sort()\n",
      "            L2.sort()\n",
      "            if L1 == L2:\n",
      "                retList.append(freq_sets[i] | freq_sets[j])\n",
      "\n",
      "    return retList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def apriori(dataset, min_support=0.5):\n",
      "    '''Generates a list of candidate itemsets.\n",
      "\n",
      "    Args:\n",
      "      dataset (array): The dataset (an array of transactions) from which to generate \n",
      "        candidate itemsets.\n",
      "      min_support (float): The minimum support threshold. Defaults to 0.5.\n",
      "\n",
      "    Returns:\n",
      "      L: The list of frequent itemsets.\n",
      "      support_data: The support data for all candidate itemsets.\n",
      "\n",
      "    '''\n",
      "\n",
      "    C1 = create_candidates(dataset)\n",
      "    D = map(set, dataset)\n",
      "    L1, support_data = support_prune(D, C1, min_support)\n",
      "    L = [L1]\n",
      "    k = 2\n",
      "    while (len(L[k - 2]) > 0):\n",
      "        Ck = apriori_gen(L[k-2], k)\n",
      "        Lk, supK = support_prune(D, Ck, min_support)\n",
      "        support_data.update(supK)\n",
      "        L.append(Lk)\n",
      "        k += 1\n",
      " \n",
      "    return L, support_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rules_from_conseq(freq_set, H, support_data, rules, min_confidence=0.7):\n",
      "    '''Generates a set of candidate rules.\n",
      "\n",
      "    Args:\n",
      "      freq_set (frozenset): The complete list of frequent itemsets.\n",
      "      H (set):  A list of frequent itemsets (of a particular length).\n",
      "      support_data (array): The support data for all candidate itemsets.\n",
      "      rules (array): A potentially incomplete set of candidate rules above the minimum \n",
      "        confidence threshold.\n",
      "      min_confidence (float): The minimum confidence threshold. Defaults to 0.7.\n",
      "\n",
      "    '''\n",
      "\n",
      "    m = len(H[0])\n",
      "    if (len(freq_set) > (m+1)):\n",
      "        Hmp1 = apriori_gen(H, m+1)\n",
      "        Hmp1 = calc_confidence(freq_set, Hmp1,  support_data, rules, min_confidence)\n",
      "        if len(Hmp1) > 1:\n",
      "            rules_from_conseq(freq_set, Hmp1, support_data, rules, min_confidence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calc_confidence(freq_set, H, support_data, rules, min_confidence=0.7):\n",
      "    '''Evaluates the generated rules.\n",
      "    \n",
      "    A measurement for quantifying the goodness of association rules is the confidence.\n",
      "    The confidence for a rule P implies H (P -> H) is defined as the support for P and H\n",
      "    divided by the support for P (support (P|H) / support(P)), where the | symbol denotes\n",
      "    the set union (thus P|H means all the items in set P or in set H).\n",
      "    \n",
      "    To calculate the confidence, we iterate through the frequent itemsets and associated\n",
      "    support data. For each frequent itemset, we divide the support of the itemset by the\n",
      "    support of the antecedent (left-hand-side of the rule).\n",
      "\n",
      "    Args:\n",
      "      freq_set (frozenset): The complete list of frequent itemsets.\n",
      "      H (set): A list of frequent itemsets (of a particular length).\n",
      "      min_support (float): The minimum support threshold.\n",
      "      rules (array): A potentially incomplete set of candidate rules above the minimum \n",
      "        confidence threshold.\n",
      "      min_confidence (float): The minimum confidence threshold. Defaults to 0.7.\n",
      "\n",
      "    Returns:\n",
      "      pruned_H: The set of candidate rules above the minimum confidence threshold.\n",
      "\n",
      "    '''\n",
      "\n",
      "    pruned_H = []\n",
      "    for conseq in H:\n",
      "        conf = support_data[freq_set] / support_data[freq_set - conseq]\n",
      "        if conf >= min_confidence:\n",
      "            print freq_set - conseq, '--->', conseq, 'conf:', conf\n",
      "            rules.append((freq_set - conseq, conseq, conf))\n",
      "            pruned_H.append(conseq)\n",
      "\n",
      "    return pruned_H"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_rules(L, support_data, min_confidence=0.7):\n",
      "    '''Generates a set of candidate rules from a list of frequent itemsets.\n",
      "\n",
      "    For each frequent itemset, we calculate the confidence of using a particular item\n",
      "    as the rule consequent (right-hand-side of the rule). By testing and merging the \n",
      "    remaining rules, we recursively create a list of pruned rules.\n",
      "\n",
      "    Args:\n",
      "      L (array): A list of frequent itemsets.\n",
      "      support_data (array): The corresponding support data for the frequent itemsets (L).\n",
      "      min_confidence (float): The minimum confidence threshold. Defaults to 0.7.\n",
      "\n",
      "    Returns:\n",
      "      rules: The set of candidate rules above the minimum confidence threshold.\n",
      "\n",
      "    '''\n",
      "\n",
      "    rules = []\n",
      "    for i in range(1, len(L)):\n",
      "        for freq_set in L[i]:\n",
      "            H1 = [frozenset([item]) for item in freq_set]\n",
      "            print \"freq_set\", freq_set, 'H1', H1\n",
      "            if (i > 1):\n",
      "                rules_from_conseq(freq_set, H1, support_data, rules, min_confidence)\n",
      "            else:\n",
      "                calc_confidence(freq_set, H1, support_data, rules, min_confidence)\n",
      "\n",
      "    return rules"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Generating test dataset and testing out functions:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a function that loads a fake dataset for testing purposes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_dataset():\n",
      "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load a dataset (list of lists) and print it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = load_dataset()\n",
      "print dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create the initial candidates and map our original sets to a Python set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C1 = create_candidates(dataset)\n",
      "D = map(set, dataset)\n",
      "print C1\n",
      "print D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[frozenset([1]), frozenset([2]), frozenset([3]), frozenset([4]), frozenset([5])]\n",
        "[set([1, 3, 4]), set([2, 3, 5]), set([1, 2, 3, 5]), set([2, 5])]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prune itemsets that don't meet minsup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "L1, support_data = support_prune(D, C1, 0.5)\n",
      "print L1\n",
      "print support_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]\n",
        "{frozenset([4]): 0.25, frozenset([5]): 0.75, frozenset([2]): 0.75, frozenset([3]): 0.75, frozenset([1]): 0.5}\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run apriori"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "L, support_data = apriori(dataset, min_support=0.5)\n",
      "print L\n",
      "print support_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])], []]\n",
        "{frozenset([5]): 0.75, frozenset([3]): 0.75, frozenset([2, 3, 5]): 0.5, frozenset([1, 2]): 0.25, frozenset([1, 5]): 0.25, frozenset([3, 5]): 0.5, frozenset([4]): 0.25, frozenset([2, 3]): 0.5, frozenset([2, 5]): 0.75, frozenset([1]): 0.5, frozenset([1, 3]): 0.5, frozenset([2]): 0.75}\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate strong rules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "generate_rules(L, support_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "freq_set frozenset([1, 3]) H1 [frozenset([1]), frozenset([3])]\n",
        "frozenset([1]) ---> frozenset([3]) conf: 1.0\n",
        "freq_set frozenset([2, 5]) H1 [frozenset([2]), frozenset([5])]\n",
        "frozenset([5]) ---> frozenset([2]) conf: 1.0\n",
        "frozenset([2]) ---> frozenset([5]) conf: 1.0\n",
        "freq_set frozenset([2, 3]) H1 [frozenset([2]), frozenset([3])]\n",
        "freq_set frozenset([3, 5]) H1 [frozenset([3]), frozenset([5])]\n",
        "freq_set frozenset([2, 3, 5]) H1 [frozenset([2]), frozenset([3]), frozenset([5])]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "[(frozenset({1}), frozenset({3}), 1.0),\n",
        " (frozenset({5}), frozenset({2}), 1.0),\n",
        " (frozenset({2}), frozenset({5}), 1.0)]"
       ]
      }
     ],
     "prompt_number": 28
    }
   ],
   "metadata": {}
  }
 ]
}
